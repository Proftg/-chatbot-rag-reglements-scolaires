import streamlit as st
import os
import sys

# Ajouter le dossier parent au path pour importer les modules
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from scraper.fetch_notes import fetch_content
from daily_check import send_email, RECEIVER_EMAIL
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="Assistant √âcole",
    page_icon="üéì",
    layout="wide"
)

# Fonction pour charger le bot (similaire √† bot.py)
@st.cache_resource
def load_rag_engine():
    try:
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import SentenceTransformerEmbeddings
        from dotenv import load_dotenv
        
        load_dotenv()
        
        base_dir = os.path.dirname(parent_dir) # AMP/
        db_dir = os.path.join(base_dir, "school_assistant", "data", "faiss_index")
        
        if not os.path.exists(db_dir):
            return None, None
            
        embedding_function = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
        db = FAISS.load_local(db_dir, embedding_function, allow_dangerous_deserialization=True)
        retriever = db.as_retriever(search_kwargs={"k": 3})
        
        # Retourner le retriever et la cl√© API (Groq ou OpenAI)
        return retriever, os.getenv("GROQ_API_KEY") or os.getenv("OPENAI_API_KEY")
    except Exception as e:
        st.error(f"Erreur chargement IA: {e}")
        return None, None

st.title("üéì Assistant Scolaire Int√©gr√©")

# Onglets pour les diff√©rentes fonctionnalit√©s
tab1, tab2, tab3 = st.tabs(["ü§ñ Chatbot R√®glements", "üìã Notes de Service", "‚öôÔ∏è Syst√®me & Logs"])

with tab1:
    st.header("Posez vos questions sur le r√®glement")
    retriever, api_key = load_rag_engine()
    
    if retriever:
        # Historique de chat
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("Ex: Comment justifier une absence ?"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                # Logique RAG avec Groq en priorit√©
                docs = retriever.invoke(prompt)
                context_text = "\n\n".join([d.page_content for d in docs])
                
                response_text = ""
                
                # Tentative 1 : Groq (priorit√© - gratuit et rapide)
                groq_key = os.getenv("GROQ_API_KEY")
                if groq_key:
                    try:
                        from langchain_groq import ChatGroq
                        llm = ChatGroq(
                            model="llama-3.3-70b-versatile",
                            groq_api_key=groq_key,
                            temperature=0
                        )
                        full_prompt = f"Tu es un assistant scolaire. Utilise ce contexte pour r√©pondre: {context_text}\n\nQuestion: {prompt}"
                        ai_msg = llm.invoke(full_prompt)
                        response_text = ai_msg.content
                    except Exception as e:
                        st.info(f"Groq indisponible : {e}")
                        groq_key = None  # Essayer la m√©thode suivante
                
                # Tentative 2 : DeepSeek/OpenAI (si Groq a √©chou√©)
                if not response_text and api_key:
                    try:
                        from langchain_openai import ChatOpenAI
                        llm = ChatOpenAI(
                            model="deepseek-chat",
                            openai_api_key=api_key,
                            openai_api_base="https://api.deepseek.com/v1",
                            temperature=0
                        )
                        full_prompt = f"Tu es un assistant scolaire. Utilise ce contexte pour r√©pondre: {context_text}\n\nQuestion: {prompt}"
                        ai_msg = llm.invoke(full_prompt)
                        response_text = ai_msg.content
                    except Exception as e:
                        st.info(f"DeepSeek/OpenAI indisponible : {e}")
                
                # Fallback : Recherche documentaire
                if not response_text:
                    response_text = f"‚ÑπÔ∏è **Mode Recherche Documentaire**\n\nVoici les extraits pertinents trouv√©s :\n\n{context_text}"
                
                st.markdown(response_text)
                st.session_state.messages.append({"role": "assistant", "content": response_text})
    else:
        st.warning("‚ö†Ô∏è L'index de recherche n'est pas pr√™t. Veuillez v√©rifier que 'setup_rag.py' a bien tourn√©.")

with tab2:
    st.header("Surveillance des Notes de Service")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown("### üìÑ Dernier contenu extrait")
        # Lire le fichier local s'il existe
        notes_file = os.path.join(parent_dir, "data", "notes_latest.txt")
        if os.path.exists(notes_file):
            with open(notes_file, "r", encoding="utf-8") as f:
                content = f.read()
            st.text_area("Contenu brut", content, height=400)
        else:
            st.info("Aucune note t√©l√©charg√©e pour le moment.")
    
    with col2:
        st.markdown("### ‚ö° Actions")
        if st.button("üîÑ Forcer la v√©rification maintenant"):
            with st.spinner("V√©rification en cours sur le site..."):
                try:
                    new_content = fetch_content()
                    if new_content:
                        st.success("‚úÖ V√©rification termin√©e ! La page a √©t√© t√©l√©charg√©e.")
                        st.rerun()
                    else:
                        st.error("‚ùå √âchec de la connexion au site.")
                except Exception as e:
                    st.error(f"Erreur: {e}")

    st.markdown("---")
    st.markdown("### üìú R√®glements extraits")
    reg_file = os.path.join(parent_dir, "data", "reglement_raw.txt")
    if os.path.exists(reg_file):
        with open(reg_file, "r", encoding="utf-8") as f:
            reg_content = f.read()
        st.text_area("Contenu du R√®glement", reg_content, height=300)
    else:
        st.info("R√®glement non trouv√©.")

with tab3:
    st.header("√âtat du Syst√®me")
    st.markdown(f"**Email de notification :** `{RECEIVER_EMAIL}`")
    
    st.markdown("### üìÇ Fichiers de donn√©es")
    data_dir = os.path.join(parent_dir, "data")
    if os.path.exists(data_dir):
        files = os.listdir(data_dir)
        for f in files:
            file_path = os.path.join(data_dir, f)
            size = os.path.getsize(file_path) / 1024
            st.text(f"- {f} ({size:.1f} KB)")
    else:
        st.warning("Dossier 'data' introuvable.")

    st.markdown("### üõ†Ô∏è Outils de maintenance")
    if st.button("üóëÔ∏è R√©initialiser la base de connaissances (Clean DB)"):
        # Logique de nettoyage simple
        st.warning("Pour nettoyer, lancez 'python clean_db.py' dans le terminal.")
