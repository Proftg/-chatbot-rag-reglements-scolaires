"""
Bot RAG am√©lior√© avec retrieval hybride et m√©tadonn√©es.
"""
import os
import sys
from pathlib import Path
from typing import List
from dotenv import load_dotenv

# Ajouter le chemin pour les imports
sys.path.append(str(Path(__file__).parents[1]))

from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from utils.logger import setup_logger

load_dotenv()
logger = setup_logger("bot_enhanced")


def format_results_with_metadata(docs: List[Document]) -> str:
    """
    Formate les r√©sultats avec m√©tadonn√©es pour affichage √† l'utilisateur.
    
    Args:
        docs: Documents trouv√©s
        
    Returns:
        Texte format√©
    """
    formatted = ""
    for i, doc in enumerate(docs, start=1):
        source = doc.metadata.get('source', 'Source inconnue')
        page = doc.metadata.get('page', '?')
        doc_type = doc.metadata.get('doc_type', 'N/A')
        section = doc.metadata.get('section_title', '')
        
        formatted += f"\nüìÑ **R√©sultat {i}** - {source} (page {page})\n"
        if section:
            formatted += f"   Section: {section}\n"
        formatted += f"   Type: {doc_type}\n"
        
        # Extrait du contenu (limit√© √† 300 caract√®res)
        content = doc.page_content.strip()
        if len(content) > 300:
            content = content[:300] + "..."
        formatted += f"   Extrait: {content}\n"
    
    return formatted


def ask_bot_enhanced(question: str, k: int = 5):
    """
    Recherche am√©lior√©e avec retrieval hybride et formatage enrichi.
    
    Args:
        question: Question de l'utilisateur
        k: Nombre de documents √† r√©cup√©rer
    """
    base_dir = Path(__file__).resolve().parents[1]
    chroma_dir = base_dir / "data" / "chroma_db_enhanced"
    
    # V√©rifier que la DB existe
    if not chroma_dir.exists():
        logger.error(f"‚ùå Base de donn√©es introuvable: {chroma_dir}")
        print("\n‚ö†Ô∏è La base de donn√©es n'existe pas encore.")
        print("   Veuillez d'abord ex√©cuter: python school_assistant/chatbot/setup_rag_enhanced.py")
        return
    
    # Charger les embeddings
    logger.info("Chargement du mod√®le d'embeddings...")
    embedding_function = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    # Charger la DB
    logger.info("Chargement de la base vectorielle...")
    db = Chroma(
        persist_directory=str(chroma_dir),
        embedding_function=embedding_function,
        collection_name="reglements_ecole"
    )
    
    # Recherche avec MMR (Maximum Marginal Relevance) pour la diversit√©
    logger.info(f"üîç Recherche pour: '{question}'")
    print(f"\nü§ñ Recherche en cours pour: '{question}'\n")
    
    docs = db.similarity_search(
        question,
        k=k,
    )
    
    if not docs:
        print("‚ùå Aucun document pertinent trouv√©.")
        logger.warning("Aucun r√©sultat trouv√©")
        return
    
    logger.info(f"‚úÖ {len(docs)} documents trouv√©s")
    
    # Pr√©parer le contexte
    context = "\n\n---\n\n".join([
        f"[Source: {doc.metadata.get('source', 'N/A')}, Page {doc.metadata.get('page', '?')}]\n{doc.page_content}"
        for doc in docs
    ])
    
    # Utiliser l'IA si disponible
    api_key = os.getenv("OPENAI_API_KEY")
    
    if api_key:
        logger.info("G√©n√©ration de la r√©ponse avec GPT...")
        try:
            llm = ChatOpenAI(
                temperature=0,
                model_name="gpt-3.5-turbo",
                openai_api_key=api_key
            )
            
            prompt = f"""Tu es un assistant scolaire sp√©cialis√© dans les r√®glements d'√©tablissement belges.

R√©ponds √† la question de l'utilisateur en te basant UNIQUEMENT sur le contexte fourni ci-dessous.

INSTRUCTIONS:
- Sois pr√©cis et concis
- Cite les sources (nom du document et num√©ro de page)
- Si la r√©ponse n'est pas dans le contexte, dis-le clairement
- Utilise un langage professionnel mais accessible

CONTEXTE:
{context}

QUESTION: {question}

R√âPONSE:"""

            response = llm.invoke(prompt)
            
            print("=" * 70)
            print("üí° R√âPONSE G√âN√âR√âE PAR L'IA")
            print("=" * 70)
            print(response.content)
            print("\n" + "=" * 70)
            print("üìö SOURCES CONSULT√âES")
            print("=" * 70)
            print(format_results_with_metadata(docs))
            
            logger.info("‚úÖ R√©ponse g√©n√©r√©e avec succ√®s")
            
        except Exception as e:
            logger.error(f"Erreur IA: {e}")
            print(f"\n‚ö†Ô∏è Erreur avec l'IA: {e}")
            print("\nüìã R√©sultats bruts de la recherche:")
            print(format_results_with_metadata(docs))
    else:
        logger.info("Mode recherche documentaire (pas de cl√© OpenAI)")
        print("‚ÑπÔ∏è Mode Recherche Documentaire (cl√© OpenAI absente)\n")
        print("=" * 70)
        print("üìö DOCUMENTS PERTINENTS TROUV√âS")
        print("=" * 70)
        print(format_results_with_metadata(docs))


if __name__ == "__main__":
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
        ask_bot_enhanced(query)
    else:
        print("Usage: python bot_enhanced.py 'Votre question ici'")
        print("\nExemple:")
        print("  python bot_enhanced.py 'Quelle est la proc√©dure en cas d'absence de professeur?'")
